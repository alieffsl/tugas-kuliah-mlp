{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports ##\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import clone\n",
    "from sklearn.datasets import load_wine,load_boston\n",
    "from sklearn.model_selection import StratifiedKFold,cross_validate\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,mean_absolute_error,mean_squared_error,r2_score,make_scorer\n",
    "from abc import ABC,abstractmethod\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "#base class for the random forest algorithm\n",
    "class RandomForest(ABC):\n",
    "    #initializer\n",
    "    def __init__(self,n_trees=100):\n",
    "        self.n_trees = n_trees\n",
    "        self.trees   = []\n",
    "    #private function to make bootstrap samples\n",
    "    def __make_bootstraps(self,data):\n",
    "        #initialize output dictionary & unique value count\n",
    "        dc   = {}\n",
    "        unip = 0\n",
    "        #get sample size\n",
    "        b_size = data.shape[0]\n",
    "        #get list of row indexes\n",
    "        idx = [i for i in range(b_size)]\n",
    "        #loop through the required number of bootstraps\n",
    "        for b in range(self.n_trees):\n",
    "            #obtain boostrap samples with replacement\n",
    "            sidx   = np.random.choice(idx,replace=True,size=b_size)\n",
    "            b_samp = data[sidx,:]\n",
    "            #compute number of unique values contained in the bootstrap sample\n",
    "            unip  += len(set(sidx))\n",
    "            #obtain out-of-bag samples for the current b\n",
    "            oidx   = list(set(idx) - set(sidx))\n",
    "            o_samp = np.array([])\n",
    "            if oidx:\n",
    "                o_samp = data[oidx,:]\n",
    "            #store results\n",
    "            dc['boot_'+str(b)] = {'boot':b_samp,'test':o_samp}\n",
    "        #return the bootstrap results\n",
    "        return(dc)\n",
    "\n",
    "    #public function to return model parameters\n",
    "    def get_params(self, deep = False):\n",
    "        return {'n_trees':self.n_trees}\n",
    "\n",
    "    #protected function to obtain the right decision tree\n",
    "    @abstractmethod\n",
    "    def _make_tree_model(self):\n",
    "        pass\n",
    "    \n",
    "    #protected function to train the ensemble\n",
    "    def _train(self,X_train,y_train):\n",
    "        #package the input data\n",
    "        training_data = np.concatenate((X_train,y_train.reshape(-1,1)),axis=1)\n",
    "        #make bootstrap samples\n",
    "        dcBoot = self.__make_bootstraps(training_data)\n",
    "        #iterate through each bootstrap sample & fit a model ##\n",
    "        tree_m = self._make_tree_model()\n",
    "        dcOob    = {}\n",
    "        for b in dcBoot:\n",
    "            #make a clone of the model\n",
    "            model = clone(tree_m)\n",
    "            #fit a decision tree model to the current sample\n",
    "            model.fit(dcBoot[b]['boot'][:,:-1],dcBoot[b]['boot'][:,-1].reshape(-1, 1))\n",
    "            #append the fitted model\n",
    "            self.trees.append(model)\n",
    "            #store the out-of-bag test set for the current bootstrap\n",
    "            if dcBoot[b]['test'].size:\n",
    "                dcOob[b] = dcBoot[b]['test']\n",
    "            else:\n",
    "                dcOob[b] = np.array([])\n",
    "        #return the oob data set\n",
    "        return(dcOob)\n",
    "      \n",
    "    #protected function to predict from the ensemble\n",
    "    def _predict(self,X):\n",
    "        #check we've fit the ensemble\n",
    "        if not self.trees:\n",
    "            print('You must train the ensemble before making predictions!')\n",
    "            return(None)\n",
    "        #loop through each fitted model\n",
    "        predictions = []\n",
    "        for m in self.trees:\n",
    "            #make predictions on the input X\n",
    "            yp = m.predict(X)\n",
    "            #append predictions to storage list\n",
    "            predictions.append(yp.reshape(-1,1))\n",
    "        #compute the ensemble prediction\n",
    "        ypred = np.mean(np.concatenate(predictions,axis=1),axis=1)\n",
    "        #return the prediction\n",
    "        return(ypred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for random forest classifier\n",
    "class RandomForestClassifierCustom(RandomForest):\n",
    "   #initializer\n",
    "    def __init__(self,n_trees=100,max_depth: int=None,min_samples_split: int=2,criterion: str='gini',class_weights='balanced'):\n",
    "        super().__init__(n_trees)\n",
    "        self.max_depth             = max_depth\n",
    "        self.min_samples_split     = min_samples_split\n",
    "        self.criterion             = criterion\n",
    "        self.class_weights         = class_weights\n",
    "\n",
    "    #protected function to obtain the right decision tree\n",
    "    def _make_tree_model(self):\n",
    "        return(DecisionTreeClassifier(max_depth             = self.max_depth,\n",
    "                                      min_samples_split     = self.min_samples_split,\n",
    "                                      criterion             = self.criterion,\n",
    "                                      class_weight          = self.class_weights))\n",
    "\n",
    "    #public function to return model parameters\n",
    "    def get_params(self, deep = False):\n",
    "        return {'n_trees':self.n_trees,\n",
    "                'max_depth':self.max_depth,\n",
    "                'min_samples_split':self.min_samples_split,\n",
    "                'criterion':self.criterion,\n",
    "                'class_weights':self.class_weights}\n",
    "\n",
    "    #train the ensemble\n",
    "    def fit(self,X_train,y_train,print_metrics=False):\n",
    "        #call the protected training method\n",
    "        dcOob = self._train(X_train,y_train)\n",
    "        #if selected, compute the standard errors and print them\n",
    "        if print_metrics:\n",
    "            #initialise metric arrays\n",
    "            accs = np.array([])\n",
    "            pres = np.array([])\n",
    "            recs = np.array([])\n",
    "            #loop through each bootstrap sample\n",
    "            for b,m in zip(dcOob,self.trees):\n",
    "                #compute the predictions on the out-of-bag test set & compute metrics\n",
    "                if dcOob[b].size:\n",
    "                    yp  = m.predict(dcOob[b][:,:-1])\n",
    "                    acc = accuracy_score(dcOob[b][:,-1],yp)\n",
    "                    pre = precision_score(dcOob[b][:,-1],yp,average='weighted')\n",
    "                    rec = recall_score(dcOob[b][:,-1],yp,average='weighted')\n",
    "                    #store the error metrics\n",
    "                    accs = np.concatenate((accs,acc.flatten()))\n",
    "                    pres = np.concatenate((pres,pre.flatten()))\n",
    "                    recs = np.concatenate((recs,rec.flatten()))\n",
    "            #print standard errors\n",
    "            print(\"Standard error in accuracy: %.2f\" % np.std(accs))\n",
    "            print(\"Standard error in precision: %.2f\" % np.std(pres))\n",
    "            print(\"Standard error in recall: %.2f\" % np.std(recs))\n",
    "\n",
    "    #predict from the ensemble\n",
    "    def predict(self,X):\n",
    "        #call the protected prediction method\n",
    "        ypred = self._predict(X)\n",
    "        #convert the results into integer values & return\n",
    "        return(np.round(ypred).astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highly correlated input features:  total_phenols  &  ['flavanoids']\n",
      "highly correlated input features:  flavanoids  &  ['total_phenols']\n",
      "Mean Accuracy: 0.94\n",
      "Mean Precision: 0.96\n",
      "Mean Recall: 0.94\n"
     ]
    }
   ],
   "source": [
    "#load the wine dataset\n",
    "dfX,sY = load_wine(return_X_y=True, as_frame=True)\n",
    "\n",
    "# #check the dimensions of these data\n",
    "# print('Dimensions of X: ',dfX.shape)\n",
    "# print('Dimensions of y: ',sY.shape)\n",
    "\n",
    "# #what unique classes exist in the label variable?\n",
    "# print('Classes in the label: ',sY.unique())\n",
    "\n",
    "# #what is the frequency of the classes in the dataset?\n",
    "# sY.hist()\n",
    "# plt.show()\n",
    "\n",
    "# #view the first 5 rows of input features\n",
    "# dfX.head(5)\n",
    "\n",
    "# #make a boxplot to view the distribution in these data\n",
    "# dfX.boxplot(figsize=(20,10),rot=45)\n",
    "# plt.show()\n",
    "\n",
    "# ## plot the pearson correlation for our input features ##\n",
    "# fig, ax = plt.subplots(figsize = (10, 10))\n",
    "# dfCorr  = dfX.corr()\n",
    "# sn.heatmap(dfCorr)\n",
    "# plt.show()\n",
    "\n",
    "#convert all correlations to positive values\n",
    "dfCorr = dfCorr.abs()\n",
    "\n",
    "#loop through rows\n",
    "for index, sRow in dfCorr.iterrows():\n",
    "    #get the valid entries\n",
    "    sCorrs = sRow[sRow.index != index]\n",
    "    sCorrs = sCorrs[sCorrs > 0.8]\n",
    "    #print out results\n",
    "    if not sCorrs.empty:\n",
    "        print('highly correlated input features: ',index,' & ',sCorrs.index.values)\n",
    "\n",
    "#create a random forest with balance class weights enabled\n",
    "rfcC = RandomForestClassifierCustom(class_weights='balanced')\n",
    "\n",
    "## train the ensemble & view estimates for prediction error ##\n",
    "rfcC.fit(dfX.values,sY.values,print_metrics=False)\n",
    "\n",
    "## use k fold cross validation to measure performance ##\n",
    "scoring_metrics = {'accuracy': make_scorer(accuracy_score),\n",
    "                   'precision': make_scorer(precision_score, average='weighted'),\n",
    "                   'recall': make_scorer(recall_score, average='weighted')}\n",
    "dcScores        = cross_validate(rfcC,dfX.values,sY.values,cv=StratifiedKFold(10),scoring=scoring_metrics)\n",
    "print('Mean Accuracy: %.2f' % np.mean(dcScores['test_accuracy']))\n",
    "print('Mean Precision: %.2f' % np.mean(dcScores['test_precision']))\n",
    "print('Mean Recall: %.2f' % np.mean(dcScores['test_recall']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.98\n",
      "Mean Precision: 0.98\n",
      "Mean Recall: 0.98\n"
     ]
    }
   ],
   "source": [
    "## import the scikit-learn models ##\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#create a random forest with balanced class weights\n",
    "rfc = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "## use k fold cross validation to measure performance ##\n",
    "scoring_metrics = {'accuracy': make_scorer(accuracy_score),\n",
    "                   'precision': make_scorer(precision_score, average='weighted'),\n",
    "                   'recall': make_scorer(recall_score, average='weighted')}\n",
    "dcScores        = cross_validate(rfc,dfX.values,sY.values,cv=StratifiedKFold(10),scoring=scoring_metrics)\n",
    "print('Mean Accuracy: %.2f' % np.mean(dcScores['test_accuracy']))\n",
    "print('Mean Precision: %.2f' % np.mean(dcScores['test_precision']))\n",
    "print('Mean Recall: %.2f' % np.mean(dcScores['test_recall']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm         Species\n",
      "0              5.1           3.5            1.4           0.2     Iris-setosa\n",
      "1              4.9           3.0            1.4           0.2     Iris-setosa\n",
      "2              4.7           3.2            1.3           0.2     Iris-setosa\n",
      "3              4.6           3.1            1.5           0.2     Iris-setosa\n",
      "4              5.0           3.6            1.4           0.2     Iris-setosa\n",
      "..             ...           ...            ...           ...             ...\n",
      "145            6.7           3.0            5.2           2.3  Iris-virginica\n",
      "146            6.3           2.5            5.0           1.9  Iris-virginica\n",
      "147            6.5           3.0            5.2           2.0  Iris-virginica\n",
      "148            6.2           3.4            5.4           2.3  Iris-virginica\n",
      "149            5.9           3.0            5.1           1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "Training Accuracy: 0.9809\n",
      "Testing Accuracy: 0.9111\n"
     ]
    }
   ],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Load Data\n",
    "df = pd.read_csv(\"iris.csv\")\n",
    "df = df.drop(\"Id\", axis = 1)\n",
    "print(df)\n",
    "\n",
    "#Train Test Split\n",
    "train = df.sample(frac = 0.7, random_state = 1)\n",
    "test = df.drop(train.index)\n",
    "\n",
    "y_train = train[\"Species\"]\n",
    "x_train = train.drop(\"Species\", axis = 1)\n",
    "\n",
    "y_test = test[\"Species\"]\n",
    "x_test = test.drop(\"Species\", axis = 1)\n",
    "\n",
    "#Training – Count Posterior\n",
    "means = train.groupby([\"Species\"]).mean() # Find mean of each class\n",
    "var = train.groupby([\"Species\"]).var() # Find variance of each class\n",
    "prior = (train.groupby(\"Species\").count() / len(train)).iloc[:,1] # Find prior probability of each class\n",
    "classes = np.unique(train[\"Species\"].tolist()) # Storing all possible classes\n",
    "\n",
    "#Classification\n",
    "def Normal(n, mu, var):\n",
    "    # Function to return pdf of Normal(mu, var) evaluated at x\n",
    "    sd = np.sqrt(var)\n",
    "    pdf = (np.e ** (-0.5 * ((n - mu)/sd) ** 2)) / (sd * np.sqrt(2 * np.pi))\n",
    "    return pdf\n",
    "\n",
    "def Predict(X):\n",
    "    Predictions = []\n",
    "    \n",
    "    for i in X.index: # Loop through each instances\n",
    "        ClassLikelihood = []\n",
    "        instance = X.loc[i]\n",
    "        for cls in classes: # Loop through each class\n",
    "            FeatureLikelihoods = []\n",
    "            FeatureLikelihoods.append(np.log(prior[cls])) # Append log prior of class 'cls'\n",
    "            for col in x_train.columns: # Loop through each feature\n",
    "                data = instance[col]\n",
    "                mean = means[col].loc[cls] # Find the mean of column 'col' that are in class 'cls'\n",
    "                variance = var[col].loc[cls] # Find the variance of column 'col' that are in class 'cls'\n",
    "                Likelihood = Normal(data, mean, variance)\n",
    "                if Likelihood != 0:\n",
    "                    Likelihood = np.log(Likelihood) # Find the log-likelihood evaluated at x\n",
    "                else:\n",
    "                    Likelihood = 1/len(train) \n",
    "                \n",
    "                FeatureLikelihoods.append(Likelihood)\n",
    "                \n",
    "            TotalLikelihood = sum(FeatureLikelihoods) # Calculate posterior\n",
    "            ClassLikelihood.append(TotalLikelihood)\n",
    "            \n",
    "        MaxIndex = ClassLikelihood.index(max(ClassLikelihood)) # Find largest posterior position\n",
    "        Prediction = classes[MaxIndex]\n",
    "        Predictions.append(Prediction)     \n",
    "    return Predictions\n",
    "\n",
    "def Accuracy(y, prediction):\n",
    "    # Function to calculate accuracy\n",
    "    y = list(y)\n",
    "    prediction = list(prediction)\n",
    "    score = 0\n",
    "    for i, j in zip(y, prediction):\n",
    "        if i == j:\n",
    "            score += 1   \n",
    "    return score / len(y)\n",
    "\n",
    "PredictTrain = Predict(x_train)\n",
    "PredictTest = Predict(x_test)\n",
    "\n",
    "print('Training Accuracy: %.4f' % round(Accuracy(y_train, PredictTrain), 5))\n",
    "print('Testing Accuracy: %.4f' % round(Accuracy(y_test, PredictTest), 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9809\n",
      "Testing Accuracy: 0.9111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train)\n",
    "SkTrain = clf.predict(x_train) # Predicting on the train set\n",
    "SkTest = clf.predict(x_test) # Predicting on the test set       \n",
    "\n",
    "print('Training Accuracy: %.4f' % round(Accuracy(y_train, SkTrain), 5))\n",
    "print('Testing Accuracy: %.4f' % round(Accuracy(y_test, SkTest), 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tugas 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\tUbahlah fungsi pemisahan menjadi Gini index dari entropi! Analisislah hasilnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "class RandomForestClassifierCustom(RandomForest):\n",
    "    #initializer\n",
    "    def __init__(self, n_trees=100, max_depth=None, min_samples_split=2, criterion='entropy', class_weights='balanced'):\n",
    "        super().__init__(n_trees)\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.criterion = criterion\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    #protected function to obtain the right decision tree\n",
    "    def _make_tree_model(self):\n",
    "        return(DecisionTreeClassifier(max_depth=self.max_depth,\n",
    "                                       min_samples_split=self.min_samples_split,\n",
    "                                       criterion=self.criterion,\n",
    "                                       class_weight=self.class_weights))\n",
    "\n",
    "    #public function to return model parameters\n",
    "    def get_params(self, deep=False):\n",
    "        return {'n_trees': self.n_trees,\n",
    "                'max_depth': self.max_depth,\n",
    "                'min_samples_split': self.min_samples_split,\n",
    "                'criterion': self.criterion,\n",
    "                'class_weights': self.class_weights}\n",
    "\n",
    "    #train the ensemble\n",
    "    def fit(self, X_train, y_train, print_metrics=False):\n",
    "        #call the protected training method\n",
    "        dcOob = self._train(X_train, y_train)\n",
    "        #if selected, compute the standard errors and print them\n",
    "        if print_metrics:\n",
    "            #initialise metric arrays\n",
    "            accs = np.array([])\n",
    "            pres = np.array([])\n",
    "            recs = np.array([])\n",
    "            #loop through each bootstrap sample\n",
    "            for b, m in zip(dcOob, self.trees):\n",
    "                #compute the predictions on the out-of-bag test set & compute metrics\n",
    "                if dcOob[b].size:\n",
    "                    yp  = m.predict(dcOob[b][:, :-1])\n",
    "                    acc = accuracy_score(dcOob[b][:, -1], yp)\n",
    "                    pre = precision_score(dcOob[b][:, -1], yp, average='weighted')\n",
    "                    rec = recall_score(dcOob[b][:, -1], yp, average='weighted')\n",
    "                    #store the error metrics\n",
    "                    accs = np.concatenate((accs, acc.flatten()))\n",
    "                    pres = np.concatenate((pres, pre.flatten()))\n",
    "                    recs = np.concatenate((recs, rec.flatten()))\n",
    "            #print standard errors\n",
    "            print(\"Standard error in accuracy: %.2f\" % np.std(accs))\n",
    "            print(\"Standard error in precision: %.2f\" % np.std(pres))\n",
    "            print(\"Standard error in recall: %.2f\" % np.std(recs))\n",
    "\n",
    "    #predict from the ensemble\n",
    "    def predict(self, X):\n",
    "        #call the protected prediction method\n",
    "        ypred = self._predict(X)\n",
    "        #convert the results into integer values & return\n",
    "        return np.round(ypred).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highly correlated input features:  total_phenols  &  ['flavanoids']\n",
      "highly correlated input features:  flavanoids  &  ['total_phenols']\n",
      "Mean Accuracy: 0.94\n",
      "Mean Precision: 0.95\n",
      "Mean Recall: 0.94\n"
     ]
    }
   ],
   "source": [
    "#load the wine dataset\n",
    "dfX,sY = load_wine(return_X_y=True, as_frame=True)\n",
    "\n",
    "#convert all correlations to positive values\n",
    "dfCorr = dfCorr.abs()\n",
    "\n",
    "#loop through rows\n",
    "for index, sRow in dfCorr.iterrows():\n",
    "    #get the valid entries\n",
    "    sCorrs = sRow[sRow.index != index]\n",
    "    sCorrs = sCorrs[sCorrs > 0.8]\n",
    "    #print out results\n",
    "    if not sCorrs.empty:\n",
    "        print('highly correlated input features: ',index,' & ',sCorrs.index.values)\n",
    "\n",
    "#create a random forest with balance class weights enabled\n",
    "rfcC = RandomForestClassifierCustom(class_weights='balanced')\n",
    "\n",
    "## train the ensemble & view estimates for prediction error ##\n",
    "rfcC.fit(dfX.values,sY.values,print_metrics=False)\n",
    "\n",
    "## use k fold cross validation to measure performance ##\n",
    "scoring_metrics = {'accuracy': make_scorer(accuracy_score),\n",
    "                   'precision': make_scorer(precision_score, average='weighted'),\n",
    "                   'recall': make_scorer(recall_score, average='weighted')}\n",
    "dcScores        = cross_validate(rfcC,dfX.values,sY.values,cv=StratifiedKFold(10),scoring=scoring_metrics)\n",
    "print('Mean Accuracy: %.2f' % np.mean(dcScores['test_accuracy']))\n",
    "print('Mean Precision: %.2f' % np.mean(dcScores['test_precision']))\n",
    "print('Mean Recall: %.2f' % np.mean(dcScores['test_recall']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\tBandingkan hasil evaluasi klasifikasi wine dataset sesuai tabel berikut ini dan analisis hasilnya!\n",
    "\n",
    "### Decision Tree (Scikit-Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.90\n",
      "Mean Precision: 0.92\n",
      "Mean Recall: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "\n",
    "# Load the wine dataset\n",
    "data = load_wine()\n",
    "dfX, sY = pd.DataFrame(data.data, columns=data.feature_names), pd.Series(data.target)\n",
    "\n",
    "# ... (rest of the code remains the same until the Decision Tree classifier)\n",
    "\n",
    "# Create a decision tree classifier with balanced class weights enabled\n",
    "dtc = DecisionTreeClassifier(class_weight='balanced')\n",
    "\n",
    "## Train the classifier & view estimates for prediction error ##\n",
    "dtc.fit(dfX.values, sY.values)\n",
    "\n",
    "## Use k-fold cross-validation to measure performance ##\n",
    "scoring_metrics = {'accuracy': make_scorer(accuracy_score),\n",
    "                   'precision': make_scorer(precision_score, average='weighted'),\n",
    "                   'recall': make_scorer(recall_score, average='weighted')}\n",
    "dc_scores = cross_validate(dtc, dfX.values, sY.values, cv=StratifiedKFold(10), scoring=scoring_metrics)\n",
    "print('Mean Accuracy: %.2f' % np.mean(dc_scores['test_accuracy']))\n",
    "print('Mean Precision: %.2f' % np.mean(dc_scores['test_precision']))\n",
    "print('Mean Recall: %.2f' % np.mean(dc_scores['test_recall']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree (Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\tBuat klasifikasi menggunakan Wine Dataset pada contoh sebelumnya menggunakan algoritma Naïve Bayes! Analisislah hasilnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9758\n",
      "Testing Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load Wine dataset\n",
    "data = load_wine()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "# Train Test Split\n",
    "train, test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "y_train = train['target']\n",
    "x_train = train.drop('target', axis=1)\n",
    "\n",
    "y_test = test['target']\n",
    "x_test = test.drop('target', axis=1)\n",
    "\n",
    "# Training - Count Posterior\n",
    "means = train.groupby([\"target\"]).mean()  # Find mean of each class\n",
    "var = train.groupby([\"target\"]).var()  # Find variance of each class\n",
    "prior = (train.groupby(\"target\").count() / len(train)).iloc[:, 1]  # Find prior probability of each class\n",
    "classes = np.unique(train[\"target\"].tolist())  # Storing all possible classes\n",
    "\n",
    "# Classification\n",
    "def Normal(n, mu, var):\n",
    "    # Function to return pdf of Normal(mu, var) evaluated at x\n",
    "    sd = np.sqrt(var)\n",
    "    pdf = (np.e ** (-0.5 * ((n - mu) / sd) ** 2)) / (sd * np.sqrt(2 * np.pi))\n",
    "    return pdf\n",
    "\n",
    "def Predict(X):\n",
    "    Predictions = []\n",
    "    \n",
    "    for i in X.index: # Loop through each instance\n",
    "        ClassLikelihood = []\n",
    "        instance = X.loc[i]\n",
    "        for cls in classes: # Loop through each class\n",
    "            FeatureLikelihoods = []\n",
    "            FeatureLikelihoods.append(np.log(prior[cls])) # Append log prior of class 'cls'\n",
    "            for col in x_train.columns: # Loop through each feature\n",
    "                data = instance[col]\n",
    "                mean = means[col].loc[cls] # Find the mean of column 'col' that are in class 'cls'\n",
    "                variance = var[col].loc[cls] # Find the variance of column 'col' that are in class 'cls'\n",
    "                Likelihood = Normal(data, mean, variance)\n",
    "                if Likelihood != 0:\n",
    "                    Likelihood = np.log(Likelihood) # Find the log-likelihood evaluated at x\n",
    "                else:\n",
    "                    Likelihood = 1 / len(train)\n",
    "                \n",
    "                FeatureLikelihoods.append(Likelihood)\n",
    "                \n",
    "            TotalLikelihood = sum(FeatureLikelihoods) # Calculate posterior\n",
    "            ClassLikelihood.append(TotalLikelihood)\n",
    "            \n",
    "        MaxIndex = ClassLikelihood.index(max(ClassLikelihood)) # Find largest posterior position\n",
    "        Prediction = classes[MaxIndex]\n",
    "        Predictions.append(Prediction)     \n",
    "    return Predictions\n",
    "\n",
    "def Accuracy(y, prediction):\n",
    "    # Function to calculate accuracy\n",
    "    y = list(y)\n",
    "    prediction = list(prediction)\n",
    "    score = 0\n",
    "    for i, j in zip(y, prediction):\n",
    "        if i == j:\n",
    "            score += 1   \n",
    "    return score / len(y)\n",
    "\n",
    "PredictTrain = Predict(x_train)\n",
    "PredictTest = Predict(x_test)\n",
    "\n",
    "print('Training Accuracy: %.4f' % round(Accuracy(y_train, PredictTrain), 5))\n",
    "print('Testing Accuracy: %.4f' % round(Accuracy(y_test, PredictTest), 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9758\n",
      "Testing Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train)\n",
    "SkTrain = clf.predict(x_train) # Predicting on the train set\n",
    "SkTest = clf.predict(x_test) # Predicting on the test set       \n",
    "\n",
    "print('Training Accuracy: %.4f' % round(Accuracy(y_train, SkTrain), 5))\n",
    "print('Testing Accuracy: %.4f' % round(Accuracy(y_test, SkTest), 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jcopml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
